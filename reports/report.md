# ‚ö†Ô∏èüõ†Ô∏è O relat√≥rio ainda est√° sendo projetado! üõ†Ô∏è‚ö†Ô∏è

# Relat√≥rio do Projeto

O intuito desse projeto, como parte do Sprint 1 da equipe PrimaType, √©, principalmente, aprender as v√°rias etapas fundamentais da ci√™ncia de dados, envolvendo coleta, limpeza/tratamento, e visualiza√ß√£o dos dados. O objetivo √© realizar uma an√°lise detalhada dos dados populacionais de diferentes esp√©cies de primatas utilizando Python e bibliotecas essenciais para o ramo.

No processo de an√°lise de dados, precisamos seguir alguns passos pra assegurar a precis√£o e concis√£o da an√°lise. Dentre esses passos, destaca-se o EDA (Exploratory Data Analysis, ou An√°lise Explorat√≥ria de Dados). O objetivo do EDA √© compreender melhor os dados, suas caracter√≠sticas, e garantir sua integridade antes de aplicar t√©cnicas avan√ßadas de an√°lise ou modelagem.

Essa etapa, que envolve limpeza, organiza√ß√£o, e transforma√ß√£o dos dados, √© a etapa seguinte da coleta dos dados que ser√£o extra√≠das as informa√ß√µes √∫teis pra tomadas de decis√£o. Fora Python, outras ferramentas podem ser √∫teis como Excel e t√©cnicas mais avan√ßadas como uso de redes neurais (intelig√™ncia artificial). A ideia √© identificar padr√µes e tend√™ncias √† fim de solucionar algum problema espec√≠fico.[^1]

## I. - Coleta de Dados

A princ√≠pio, coletamos os dados que ser√£o analisados. No escopo desse projeto, √© o primates_dataset.csv, um arquivo CSV, mas poderiam tamb√©m ser extra√≠dos de um banco de dados, APIs, dentre outras fontes.

Com o intuito de facilitar a visualiza√ß√£o dos dados, foi criado uma classe de utilidade chamada **Query**. Essa classe √© respons√°vel por tratar o CSV como um banco de dados relacional, trazendo suporte √† consultas em formato similar √† ORMs como TypeORM, SQLAlchemy, Eloquent, dentre outros. Pra se parecer com a sintaxe de ORMs, a classe tem m√©todos encade√°veis que visam a padroniza√ß√£o do SQL padr√£o ANSI.[^2]

## II. - An√°lise das vari√°veis

Em segundo passo, conhecemos as vari√°veis. Entender o que cada uma delas representa, suas unidades de medida. Essa etapa pode envolver tanto an√°lise do pr√≥prio cientista de dados quanto de leitura da documenta√ß√£o dos dados, se dispon√≠vel, √† fim de obter mais contexto sobre como os dados foram coletados, e suas limita√ß√µes.

### II.1 - Quais s√£o as vari√°veis dispon√≠veis?

O CSV cont√©m as colunas:

-   species_id -> Identificador de cada linha de 1 a 150;
-   species_name -> Nome da esp√©cie de primata. S√£o elas:
    -   Gorilla;
    -   Chimpanzee;
    -   Orangutan;
    -   Gibbon;
    -   Bonobo;
    -   Lemur;
    -   Tarsier;
    -   Howler Monkey;
    -   Spider Monkey;
    -   Macaque.

Todos os dados a seguir s√£o referentes √† devida esp√©cie correspondente (na mesma linha).

-   population -> Quantidade de esp√©cimes vivos.
-   year -> referente √† qual ano √© a informa√ß√£o dessa linha. Os anos v√£o de 2020 at√© 2006.
-   habitat_region -> Regi√£o em que habita a esp√©cie. S√£o elas:
    -   Central Africa;
    -   West Africa;
    -   Madagascar;
    -   Southeast Asia;
    -   East Asia;
    -   South America.
-   diet -> A dieta da esp√©cie de primata. Pode ser:
    -   Herbivore;
    -   Omnivore;
    -   Frugivore;
    -   Insectivore.
-   avg_lifespan -> Um valor que representa quantos anos √© o tempo de vida m√©dio de um esp√©cime.
-   social_behavior -> O comportamento social das esp√©cies. Pode ser:
    -   Group;
    -   Solitary;
    -   Pair.
-   genetic_variation -> A varia√ß√£o gen√©tica da esp√©cie.
-   health_status -> Classifica√ß√£o que indica o qu√£o amea√ßada de extin√ß√£o est√° a esp√©cie. S√£o poss√≠veis valores:
    -   Healthy;
    -   Near Threatened.
    -   Vulnerable;
    -   Endangered;
    -   Critically Endangered;
-   latitude -> A coordenada latitudinal da regi√£o em que habita a esp√©cie.
-   longitude -> A coordenada longitudinal da regi√£o em que habita a esp√©cie.

### II.2 - Questionamentos referentes √†s vari√°veis

Dos dados reunidos acima, √© poss√≠vel inferir sobre cada um deles seus tipos primitivos. No entanto, dois levantam o questionamento: genetic_variation e health_status.

#### II.2.1 - genetic_variation

A vari√°vel genetic_variation implica varia√ß√£o gen√©tica da esp√©cie, mas varia√ß√£o √† oque? De acordo com [algumas informa√ß√µes](https://humanorigins.si.edu/evidence/genetics#:~:text=The%20DNA%20difference%20with%20gorillas,Asian%20great%20ape%2C%20the%20orangutan.), os valores batem com a varia√ß√£o gen√©tica do gene da esp√©cie referente o gene humano. Mas nas mesmas fontes, outros valores s√£o providenciados, e discutir a veracidade do fornecido pelo CSV √© plaus√≠vel.[^3]

#### II.2.2 - health_status

Podemos inferir que esses valores se referem √† classifica√ß√£o determinada pela [Uni√£o Internacional pela Conserva√ß√£o da Natureza](https://www.iucn.org/)Uni√£o Internacional pela Conserva√ß√£o da Natureza. Na amostragem dos dados II.1, os dados referentes √† vari√°vel "health_status" j√° est√£o em ordem (de cima pra baixo) pra mais pr√≥xima da extin√ß√£o.[^4]

#### II.2.3 - latitude & longitude

Em primeira inst√¢ncia uma pessoa poderia se perguntar aonde se referem as coordenadas fornecidas em cada linha. Elas levam para a localiza√ß√£o indicada pela vari√°vel "habitat_region". Cabe √† etapa de limpeza dos dados verificar se isso √© veross√≠mil pra todas as linhas.

### II.3 - Transforma√ß√£o das vari√°veis

√â uma etapa importante da an√°lise p√≥s-coleta de dados que verifiquemos quais vari√°veis possuem mais correla√ß√£o com o que desejamos. Para o escopo do projeto atual, percebe-se que as vari√°veis est√£o satisfat√≥rias com sua exibi√ß√£o, talvez por exce√ß√£o de "genetic_variation", que, ao inv√©s de um float entre 0.00 √† 0.10, poderia ser uma porcentagem. Depende de cada cientista. Al√©m disso, a separa√ß√£o de dois campos "latitude" e "longitude" pode desagradar quem preferisse um √∫nico campo "coordinates".

### II.4 - Vari√°veis mais Importantes

Em alguns projetos, √© necess√°ria uma investiga√ß√£o sobre quais das vari√°veis possuem mais correla√ß√£o com o objetivo. Como o intuito desse projeto √© analisar a varia√ß√£o da popula√ß√£o dessas esp√©cies, identificar e visualizar as tend√™ncias populacionais ao longo do tempo, fica evidente que as nossas vari√°veis que receber√£o mais destaque ser√£o "population" e "year".

## III. - Limpeza dos Dados

Uma das etapas mais importantes da An√°lise Explorat√≥ria de Dados √© a limpeza dos dados. As informa√ß√µes que temos, n√£o necessariamente, podem estar 100% corretas. √â nosso trabalho identificar poss√≠veis discrep√¢ncias, como anomalias, dados err√¥neos, valores ausentes e inconsist√™ncias como duplicatas.

### III.1 - Tratamento de Valores Ausentes

Come√ßaremos a limpeza dos dados identificando e tratando valores ausentes. Podemos fazer isso removendo linhas ou colunas com muitos valores ausentes, ou adicionando nossos pr√≥prios valores como indica√ß√£o de
valores nulos (adicionando 0, por exemplo) ou informa√ß√µes previstas de acordo com os outros dados.

Para fazer isso, foi criado a classe **DataConsistencyValidator** e seu m√©todo **verify_all_empty_entries**. Esse √© respons√°vel por percorrer, linha a linha, os dados fornecidos, e ao final, indica quais linhas tiveram valores vazios, e em qual coluna exatamente. Gra√ßas √† ele, foi poss√≠vel tirar essa informa√ß√£o:

-   Vazio encontrado na linha 4, coluna 'habitat_region'
-   Vazio encontrado na linha 13, coluna 'population'
-   Vazio encontrado na linha 54, coluna 'habitat_region'
-   Vazio encontrado na linha 63, coluna 'population'

Os valores perdidos em "habitat_region" s√£o f√°ceis de prever: Pegaremos das outras linhas essa informa√ß√£o e preencheremos na m√£o mesmo. Ser√° preenchido na m√£o pois o CSV √© pequeno, no entanto, em CSVs maiores, seria necess√°ria a cria√ß√£o de outro m√©todo na classe **DataConsistencyValidator** ou criar uma classe apropriada pra essa etapa da limpeza.

Na linha 4, a esp√©cie "Gibbon" est√° sem habitat_region. Vemos em outras linhas da esp√©cie "Gibbon" que essa informa√ß√£o √© "Southeast Asia". Na linha 54 vemos o mesmo caso, tamb√©m com a esp√©cie "Gibbon", ent√£o tamb√©m ser√° preenchido com o dado "Southeast Asia".

#### III.1.1 - O que fazer para tratar valores ausentes

Pro caso das linhas 13 e 63, o valor da popula√ß√£o da esp√©cie "Orangutan" est√° faltando. Para isso, podemos ou prever qual era a popula√ß√£o do momento pra substitu√≠-lo, ou deletar a informa√ß√£o.

Se a quantidade de dados ausentes √© pequena e n√£o compromete significativamente a integridade da an√°lise, optamos pela remo√ß√£o das linhas com valores ausentes. Isso √© totalmente v√°lido, se houver um n√∫mero suficiente de outras observa√ß√µes para realizar an√°lises sem esses registros.[^5]

Entretanto, se a remo√ß√£o das linhas n√£o √© desej√°vel devido √† perda de dados, √© plaus√≠vel considerarmos estimar o valor ausente com base em uma m√©dia ou outra medida central dos valores dispon√≠veis.

A escolha entre essas abordagens depende do contexto espec√≠fico do estudo e das caracter√≠sticas dos dados. Enquanto a remo√ß√£o garante que a an√°lise seja feita apenas com dados originais e completos, ela reduz a quantidade total de dados dispon√≠veis. J√° a estima√ß√£o do valor ausente permite manter mais dados para a an√°lise, mas introduz uma estimativa que pode afetar a precis√£o dos resultados.

Cabe ao cientista/analista de dados decidir baseado em seu contexto: revisar as diretrizes/normas aplic√°veis √† sua an√°lise, garantindo que as escolhas sejam adequadas e bem fundamentadas, e tamb√©m deve-se considerar a consulta de especialistas ou colegas do projeto.[^6]

#### III.1.2 - Manter a transpar√™ncia

Na prepara√ß√£o de um relat√≥rio ou visualiza√ß√£o dos dados em que houve imputa√ß√µes ou estimativas de valores ausentes, √© importante fornecer transpar√™ncia sobre como esses dados foram tratados. Poss√≠veis pr√°ticas:

-   Legenda ou Nota de Rodap√© no Gr√°fico/Relat√≥rio
-   Marcadores Visuais
-   Discuss√£o no Texto

Mostrar transpar√™ncia aumenta a credibilidade do trabalho, demonstrando a considera√ß√£o atenta quanto ao tratamento de dados ausentes, al√©m de ajudar os leitores a interpretarem corretamente os resultados, entendendo o impacto que valores ausentes tratados podem ter no resultado. Ademais, possibilita os envolvidos com o projeto de compreenderem melhor as decis√µes aplicadas no processamento, fortalecendo a confian√ßa.

#### III.1.3 - O que foi feito

Usando o aprendizado anterior, decidiu-se estimar os valores ausentes ante exclu√≠-los, visando manter mais dados para an√°lise.

Fazendo uso da nossa **Query** para capturar todas as linhas referentes √† orangutangos, tivemos que os valores faltantes est√£o precedidos de uma popula√ß√£o de 700 (anos 2013 e 2018) e seguidos de uma popula√ß√£o de 750 (anos 2015 e 2020). Como a popula√ß√£o cresceu 50 em 2 anos, podemos inferir pela m√©dia que houve um crescimento de 25 por ano. Conclui-se que um valor poss√≠vel a se considerar pra preencher os valores ausentes seria 25.

Em futuras visualiza√ß√µes, como gr√°ficos, haver√° a transpar√™ncia de indicar o preenchimento artificial desses dados, como neste mesmo documento.

### III.2 - Corre√ß√£o de Inconsist√™ncias

Antes de termos falado sobre os valores vazios na coluna "population", houve valores vazios na coluna "habitat_region" que precisaram ser preenchidos. √â importante que certos valores qualitativos ou quantitativos arbitr√°rios permane√ßam consistentes entre si. As colunas "habitat_region", "diet", "social_behavior", "genetic_variation", "health_status", "latitude" e "longitude" n√£o fazem sentido mudarem no contexto do projeto. Pra esses valores mudarem, muitos anos precisam se passar, muito mais do que a faixa 2006-2020 que temos no nosso banco atual.

A coluna mais prov√°vel de se mudar nessa pequena faixa de tempo seria "health_status", j√° que isso √© um dado qualitativo determinado pelo √≥rg√£o internacional falado anteriormente. No entanto, pro nosso projeto, n√£o houve quaisquer mudan√ßas. No mesmo ponto em que isso foi resolvido tamb√©m foi falado sobre confirmar que as coordenadas (latitude e longitude) se adequam com a fornecida pela "habitat_region".

Pra cada esp√©cie, os valores que s√£o, sim, esperados terem mudan√ßas hora ou outra, s√£o os das colunas "population", "year", e "avg_lifespan".

Para confirmar tudo isso, foi-se criado o m√©todo **verify_column_consistency** na classe **DataConsistencyValidator**. Esse m√©todo verifica, dado uma base de dados e as devidas colunas, se todos os dados se encaixam com o primeiro valor fornecido pra cada esp√©cie.

Utilizando esse m√©todo, foi poss√≠vel inferir que todos os dados est√£o consistentes ap√≥s o preenchimento dos valores ausentes, possibilitando que sigamos em frente no tratamento.

### III.3 - Remo√ß√£o de Outliers

"Outliers" s√£o valores que se desviam significativamente dos outros dados em um conjunto. Podem ser causados por erros de medi√ß√£o, entrada incorreta de dados, ou at√© mesmo valores leg√≠timos, representando variabilidade real no conjunto de dados em quest√£o. Eles podem distorcer estat√≠sticas descritivas como m√©dia e desvio padr√£o, afetar modelos estat√≠sticos de Machine Learning e influenciar negativamente na visualiza√ß√£o de dados. Em resumo, s√£o dados an√¥malos que podem distorcer a an√°lise.

A identifica√ß√£o e remo√ß√£o dos outliers √© uma etapa importante na an√°lise de dados, mas deve ser realizada com cuidado para garantir que os resultados finais sejam precisos. Poss√≠veis formas de identificar outliers s√£o por meio de m√©todos estat√≠sticos e pela visualiza√ß√£o direta dos dados.[^7]

#### III.2.1 - M√©todo Estat√≠stico Z-Score

O Z-Score √© uma pontua√ß√£o que mede quantos desvios padr√£o um valor est√° distante da m√©dia. Valores de Z-Score acima de 3 ou abaixo de -3 (ou, simplesmente, o valor absoluto do Z-Score acima de 3) s√£o geralmente considerados outliers. Pontua√ß√µes positivas indicam que o valor est√° acima da m√©dia, enquanto que a pontua√ß√£o negativa indica que est√° abaixo dessa m√©dia. Serve pra determinar a volatilidade dos dados do conjunto.

O desvio padr√£o √© essencialmente um reflexo da quantidade de variabilidade dentro desse conjunto. Segundo estudos decorrentes desde a d√©cada de 1960[^8], 99,7% dos valores prestativos contam dentro desse intervalo de -3 a 3. No entanto, ele √© t√£o preciso quanto os dados inseridos nele, logo, n√£o √© imune √† dados falsos ou inseridos err√¥neamente. √â por isso que a etapa de remo√ß√£o de anomalias √© uma das √∫ltimas na limpeza.[^9]

1. Calculamos a m√©dia dos valores da coluna de interesse;
2. Da mesma forma, calculamos o desvio padr√£o;
3. Calculamos o Z-Score pra cada valor na coluna subtraindo o valor pela m√©dia e dividindo pelo desvio padr√£o;
4. Identificar todos os valores que, absolutos, s√£o maiores que 3.

Pra atingir isso, foi-se criado o m√©todo **z_score** na classe **Outliers**. Essa classe servir√° pra comportar os m√©todos de rastreamento de anomalias, sendo o m√©todo z_score, a m√©trica apresentada agora.

Com esse m√©todo, foi poss√≠vel notar que nossos dados populacionais e de m√©dia de vida n√£o est√£o vol√°teis.

#### III.2.2 - M√©todo Estat√≠stico Interquartile Range

O IQR √© a diferen√ßa entre o terceiro quartil (Q3) e o primeiro quartil (Q1) do conjunto de dados. Valores que est√£o abaixo de Q1 - 1.5 _ IQR ou acima de Q3 + 1.5 _ IQR s√£o, normalmente, considerados outliers.[^10]

1. Encontramos o valor do primeiro quartil;
2. Encontramos o valor do terceiro quartil;
3. Calculamos o IQR subtraindo o terceiro quartil do primeiro;
4. Identificamos todos os valores menores que Q1 - 1.5IQR e maiores que Q3 + 1.5IQR.

Pra cumprir com esse fim, foi criado o m√©todo **interquartile_range**, tamb√©m na classe **Outliers**. Com esse m√©todo, foi poss√≠vel notar que os dados de m√©dia de vida n√£o est√£o muito discrepantes. No entanto, h√° registro de dados discrepantes quanto √† popula√ß√£o, especificamente, de chimpanz√©s.

No entanto, deve-se ter ci√™ncia do contexto do dom√≠nio dos dados e an√°lise da sensibilidade para interpretar corretamente os outliers. Nem todos os valores extremos s√£o, necessariamente, erros ou dados a serem removidos. Ao analisar, visualmente, o CSV, vemos que a popula√ß√£o das esp√©cies √© aproximadamente a mesma, com pouca varia√ß√£o, exceto para os chimpanz√©s, que t√™m, realmente, uma popula√ß√£o mais alta do que das demais. No entanto, isso n√£o √© um erro: √© simplesmente uma observa√ß√£o de que h√° um grupo com popula√ß√£o maior.[^11]

Sendo assim, conclui-se que nenhuma remo√ß√£o ou altera√ß√£o desses valores ser√° necess√°ria.

## IV. - Agrega√ß√£o de Dados

Saindo da etapa de limpeza, remo√ß√£o e tratamento dos dados, temos o processo de resumir os conjuntos de dados. Coletar e agrupar os dado em um formato compacto permite compreender mais facilmente e representa melhor vis√µes estat√≠sticas. Dados agrupados facilitam o processo de tomada de decis√£o.[^12]

Como at√© agora todo o c√≥digo tem sido escrito em orienta√ß√£o a objetos, faz muito sentido separarmos cada dado de primata em uma classe pr√≥pria **Primate**. Essa classe separa todas as informa√ß√µes necess√°rias em seus devidos tipos primitivos, ou n√£o: alguns dados qualitativos e outras informa√ß√µes mais espec√≠ficas tiveram tipagens pr√≥prias tamb√©m, definidas na utilidade **Types**. A classe Primate tamb√©m refor√ßa a tipagem lan√ßando exce√ß√µes (erros) caso seja inserido um dado inv√°lido, pois, em se tratando da an√°lise de dados, √© plaus√≠vel querer sensibilidade em rela√ß√£o ao que estamos trabalhando. Toda informa√ß√£o importa e deve ser exatamente o que esperamos (ou precisamos) que seja.

No entanto, como queremos que nossa classe Primate apenas comporte as informa√ß√µes referentes aos primatas que estamos estudando, manter a complexidade de c√≥digo de valida√ß√£o de entrada dos dados, bem como assegurar a estrutura de cada uma distorce o prop√≥sito da classe. Por conta disso, foi decidido criar um arquivo **PrimateFactory**, que, como em Java, √© respons√°vel pela complexidade extra na cria√ß√£o da classe que desejamos. Assim, cada arquivo bate exatamente com a expectativa de que teria dentro.

## IV. - Transforma√ß√£o dos Dados

Tendo os conjuntos de dados sido devidamente agregados e separados em suas estruturas mais apropriadas, uma importante etapa √© a normaliza√ß√£o / padroniza√ß√£o destes. Essa etapa est√°, principalmente, ligada √† Machine Learning (aprendizado de m√°quina), redes neurais e modelos de linguagem. Portanto, √© muito comum explorarmos a biblioteca scikit-learn.

Scikit-learn √© uma biblioteca de Python desenvolvida especificamente para a aplica√ß√£o pr√°tica do machine learning. Disp√µe de ferramentas simples e eficientes para an√°lise preditiva de dados, √© reutiliz√°vel, c√≥digo aberto e acess√≠vel, principalmente por ter sido constru√≠da em cima de outras bibliotecas muito bem conhecidas e consolidadas: NumPy, SciPy e matplotlib.[^13]

Suas principais aplica√ß√µes envolvem pr√©-processamento de dados, classifica√ß√£o, regress√£o, clusteriza√ß√£o, redu√ß√£o de dimensionalidade, ajuste de par√¢metros, dentre outras funcionalidades. Nem todas ser√£o vistas devido ao escopo desse projeto, mas ser√° bem explorada.[^13]

### IV.1 - Codifica√ß√£o de Dados Categ√≥ricos

Dados categ√≥ricos (qualitativos) t√™m esse nome por serem divididos, separados em categorias. Exemplos incluem cores, marcas, etc. Os modelos de Machine Learning esperam receber dados num√©ricos, na grande maioria dos casos n√£o √© poss√≠vel usar vari√°veis categ√≥ricas nesses modelos. √â necess√°rio converter eles em vari√°veis num√©ricas, de uma forma que mantenha a informa√ß√£o e a rela√ß√£o entre os dados.[^14]

# Bibliografia

[^1]: ENTENDA o que √© an√°lise de dados, quais os processos envolvidos e como implementar na sua empresa. Cinnecta. Dispon√≠vel em: https://cinnecta.com/conteudos/analise-de-dados/ . Acesso em: 2 de jul. de 2024.
[^2]: ANSI SQL O idioma para sistemas de gerenciamento de banco de dados relacional. FasterCapital. Dispon√≠vel em: https://fastercapital.com/pt/contente/ANSI-SQL--O-idioma-para-sistemas-de-gerenciamento-de-banco-de-dados-relacional.html#:~:text=A%20ANSI%20SQL%2C%20ou%20American,padr%C3%A3o%20atual%20ANSI%20SQL%3A%202016. . Acesso em: 2 de jul. de 2024.
[^3]: GENETIC Evidence. The Smithsonian National Museum of Natural History. Dispon√≠vel em: https://humanorigins.si.edu/evidence/genetics . Acesso em: 29 de jun. de 2024.
[^4]: IUCN, IUCN. P√°gina inicial. Dispon√≠vel em: https://www.iucn.org/ . Acesso em: 29 de jun. de 2024.
[^5]: J√öNIOR, Cl√©bio de Oliveira. Feature Engineering: T√©cnicas para lidar com dados faltantes em um projeto de ci√™ncia de dados. Medium. Dispon√≠vel em: https://medium.com/data-hackers/feature-engineering-t%C3%A9cnicas-para-lidar-com-dados-faltantes-em-um-projeto-de-ci%C3%AAncia-de-dados-debdd57eb662 . Acesso em: 2 de jul. de 2024.
[^6]: MACHINE Learning: Preenchimento de zeros - Manipula√ß√£o de dados faltantes. Awari. Dispon√≠vel em: https://awari.com.br/machine-learning-preenchimento-de-zeros-manipulacao-de-dados-faltantes-2/?utm_source=blog&utm_campaign=projeto+blog&utm_medium=Machine%20Learning:%20Preenchimento%20de%20zeros%20-%20Manipula%C3%A7%C3%A3o%20de%20dados%20faltantes . Acesso em: 2 de jul. de 2024.
[^7]: MEDEIROS, Ricardo. Tratando Valores Outliers em um DataFrame usando Python. dio. Dispon√≠vel em: https://www.dio.me/articles/tratando-valores-outliers-em-um-dataframe-usando-python . Acesso em: 2 de jul. de 2024.
[^8]: Z-SCORE: saiba o que √© e como funciona. Mais Retorno, 2022. Dispon√≠vel em: https://maisretorno.com/portal/termos/z/z-score . Acesso em: 30 de jun. de 2024.
[^9]: Z-SCORE. Oracle Help Center. Dispon√≠vel em: https://docs.oracle.com/cloud/help/pt_BR/pbcs_common/PFUSU/insights_metrics_Z-Score.htm#PFUSU-GUID-640CEBD1-33A2-4B3C-BD81-EB283F82D879 . Acesso em: 30 de jun. de 2024.
[^10]: BHANDARI, Pritha. How to Find Interquartile Range (IQR) | Calculator & Examples. Scribbr. Dispon√≠vel em: https://www.scribbr.com/statistics/interquartile-range/ . Acesso em: 2 de jul. de 2024.
[^11]: MACIEL, Prof. Fernanda. Excluir Outliers? Usar m√©dia ou mediana? | Prof. Fernanda Maciel. YouTube, 23 de ago. de 2021. 3m31s. Dispon√≠vel em: https://www.youtube.com/watch?v=o3uTAZyROI8 . Acesso em: 2 de jul. de 2024.
[^12]: SPASOJEVIC, Anastasia. O que √© agrega√ß√£o de dados?. phoenixNAP Global IT Services. Dispon√≠vel em: https://www.phoenixnap.pt/gloss%C3%A1rio/Agrega%C3%A7%C3%A3o-de-dados . Acesso em: 5 de jul. de 2024.
[^13]: A Biblioteca scikit-learn - Python: o que √©, para que serve. Did√°tica Tech. Dispon√≠vel em: https://medium.com/@pedrorp/guia-de-codificadores-de-atributos-categ%C3%B3ricos-em-machine-learning-60a9f22c9a3b . Acesso em: 3 de jul. de 2024.
[^14]: PASSOS, Pedro C√©sar Ribeiro. Guia de Codificadores de Atributos Categ√≥ricos em Machine Learning. Dispon√≠vel em: https://medium.com/@pedrorp/guia-de-codificadores-de-atributos-categ%C3%B3ricos-em-machine-learning-60a9f22c9a3b . Acesso em: 3 de jul. de 2024.
